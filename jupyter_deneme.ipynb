{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import torch.utils.data as data_utils\n",
    "import re\n",
    "#from pytorch_pretrained_bert import BertTokenizer, BertModel, BertConfig\n",
    "# def pad_sequence(sequence,max_length):\n",
    "#     if len(sequence)<max_length:\n",
    "#         sequence += (max_length-len(sequence))*[0]\n",
    "#     return sequence\n",
    "\n",
    "\n",
    "\n",
    "def embeddings_from_dataset(X, tokenizer, bert_model):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #X = [tokenizer.tokenize('[CLS] ' + sent + ' [SEP]') for sent in X] # Appending [CLS] and [SEP] tokens - this probably can be done in a cleaner way\n",
    "    #X_test = [tokenizer.tokenize('[CLS] ' + sent + ' [SEP]') for sent in X_test] # Appending [CLS] and [SEP] tokens - this probably can be done in a cleaner way\n",
    "    #X = [text[:512] if len(text)>512 else text for text in X]\n",
    "    #X_test = [text[:512] if len(text)>512 else text for text in X_test]\n",
    "    #X_tokens = [tokenizer.convert_tokens_to_ids(sent) for sent in X]\n",
    "    encoded_dict = tokenizer.batch_encode_plus([text_preprocessing(post) for post in X],\n",
    "            padding=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length= MAX_LEN,             \n",
    "            pad_to_max_length=True,\n",
    "            truncation = True,\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask=True)\n",
    "\n",
    "    token_ids = encoded_dict.get('input_ids')\n",
    "    attention_mask = encoded_dict.get('attention_mask')\n",
    "    tokenization_data = data_utils.TensorDataset(token_ids, attention_mask)\n",
    "    batch_size = 256\n",
    "    token_data_loader = data_utils.DataLoader(tokenization_data, batch_size=batch_size)\n",
    "\n",
    "    train_embeddings = []\n",
    "    #test_embeddings = []\n",
    "\n",
    "    #results = torch.zeros((len(X_train_tokens), bert_model.config.hidden_size)).long()\n",
    "    with torch.no_grad():\n",
    "        for batch_no, data in enumerate(token_data_loader):\n",
    "            if batch_no%10 == 0:\n",
    "                print(f\"Processed_data : {batch_no*batch_size}\")\n",
    "            \n",
    "            ids = data[0].to(device)\n",
    "            masks = data[1].to(device)\n",
    "            outputs = bert_model(input_ids = ids, attention_mask = masks)\n",
    "            embeddings = outputs[0][:, 0, :]\n",
    "            #embeddings = outputs[0][0][0] #This only takes CLS embedding\n",
    "            train_embeddings.append(embeddings.cpu())\n",
    "            #results[stidx] = embeddings.cpu()\n",
    "        \n",
    "        # for stidx in range(len(X_test)):\n",
    "        #     tokens = X_test_tokens[stidx]\n",
    "        #     tokens_t = torch.LongTensor(tokens)#.to(device)\n",
    "        #     segment_t = torch.LongTensor([1] * len(tokens))#.to(device)\n",
    "        #     outputs = bert_model(tokens_t.unsqueeze(0),segment_t.unsqueeze(0))\n",
    "        #     embeddings = outputs[0][0][0] #This only takes CLS embedding\n",
    "        #     test_embeddings.append(embeddings.cpu())\n",
    "    return torch.cat(train_embeddings)\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "# Load the BERT tokenizer\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model,optimizer,criterion,loader, use_sf = True):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_preds = 0\n",
    "    for data in loader:\n",
    "        if use_sf == True:\n",
    "            x,side_features,label = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "            classifier_input = torch.cat((x,side_features),dim=1)\n",
    "        else:\n",
    "            x,label = data[0].to(device), data[1].to(device)\n",
    "            classifier_input = x\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(classifier_input)\n",
    "        loss = criterion(logits,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        correct_preds += (preds == label).cpu().numpy().sum()\n",
    "    \n",
    "    return total_loss/len(loader.dataset), correct_preds/len(loader.dataset)    \n",
    "\n",
    "def test_model(model,criterion,loader, use_sf = True):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_preds = 0\n",
    "    for data in loader:\n",
    "        if use_sf == True:\n",
    "            x,side_features,label = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "            classifier_input = torch.cat((x,side_features),dim=1)\n",
    "        else:\n",
    "            x,label = data[0].to(device), data[1].to(device)\n",
    "            classifier_input = x\n",
    "        logits = model(classifier_input)\n",
    "        loss = criterion(logits,label)\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        correct_preds += (preds == label).cpu().numpy().sum()\n",
    "\n",
    "    \n",
    "    return total_loss/len(loader.dataset), correct_preds/len(loader.dataset)\n",
    "    \n",
    "class BertNet(nn.Module):\n",
    "    def __init__(self, bert_model, tokenizer, input_size = 768):\n",
    "        super().__init__()\n",
    "        self.bert_model = bert_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_size, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "        #self.fc3 = nn.Linear(50,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self,x,side_features=None):\n",
    "        embs = embeddings_from_dataset([x],self.tokenizer, self.bert_model)\n",
    "        if side_features != None:\n",
    "            classifier_input = torch.cat((embs,side_features),dim=1)\n",
    "        else:\n",
    "            classifier_input = embs\n",
    "        y_hat = self.forward(classifier_input)\n",
    "        preds = np.where(y_hat>0.5, 1, 0)\n",
    "        return preds[0][0]\n",
    "\n",
    "\n",
    "class SFNet(nn.Module):\n",
    "    def __init__(self, input_size = 7):\n",
    "        super().__init__()\n",
    "        self.classifier_1 = nn.Sequential(\n",
    "            nn.Linear(input_size, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30,7)\n",
    "        )\n",
    "        self.classifier_2 = nn.Sequential(\n",
    "            nn.Linear(7, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_hidden = self.classifier_1(x)\n",
    "        x = x + x_hidden\n",
    "        x = self.classifier_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MAX_LEN = 64\n",
    "\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data, tokenizer, max_len=MAX_LEN):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length= max_len,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            truncation = True,\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "import random\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs, len_train, freeze_bert=False, pretrained_model = None, side_feature_size = 0):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    if pretrained_model == None:\n",
    "        bert_classifier = BertClassifier(freeze_bert=freeze_bert, side_feature_size=side_feature_size)\n",
    "    else:\n",
    "        bert_classifier = pretrained_model\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len_train * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader,optimizer,scheduler, val_dataloader=None, epochs=4, evaluation=False, use_sf = False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            model.zero_grad()\n",
    "\n",
    "            if use_sf:\n",
    "                b_input_ids, b_attn_mask, b_sf, b_labels = tuple(t.to(device) for t in batch)\n",
    "                logits = model(b_input_ids, b_attn_mask, b_sf)\n",
    "            else:\n",
    "                b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "                logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            \n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            \n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader, use_sf)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader, use_sf, print_cm=False):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        if use_sf:\n",
    "            b_input_ids, b_attn_mask, b_sf, b_labels = tuple(t.to(device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                logits = model(b_input_ids, b_attn_mask, b_sf)\n",
    "        else:\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "        #print(cm)\n",
    "        for i in range(len(preds)):\n",
    "            all_labels.append(b_labels[i].item())\n",
    "            all_preds.append(preds[i].item())\n",
    "\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "    if print_cm:\n",
    "        print(confusion_matrix(np.array(all_labels),np.array(all_preds)))\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, side_feature_size=0, freeze_bert=False):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768+side_feature_size, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768+side_feature_size, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, side_features=None):\n",
    "        \n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "        if side_features != None:\n",
    "            classifier_input = torch.cat((last_hidden_state_cls, side_features),dim=1)\n",
    "        else:\n",
    "            classifier_input = last_hidden_state_cls\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(classifier_input)\n",
    "\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifierFinal(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, side_feature_size=0, freeze_bert=False):\n",
    "\n",
    "        super(BertClassifierFinal, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768+side_feature_size, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(768, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, 10)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(10+side_feature_size, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, side_features=None):\n",
    "        \n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "        projection_cls = self.projector(last_hidden_state_cls[:,:768])\n",
    "        if side_features != None:\n",
    "            classifier_input = torch.cat((projection_cls, side_features),dim=1)\n",
    "        else:\n",
    "            classifier_input = projection_cls\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(classifier_input)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"Clout\",\"Tone\",\"Linguistic\",\"death\",\"WC\",\"Cognition\",\"WPS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASD\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\Users\\ASD\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train:  162439 len test:  69618\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "#CLASSİCAL METHODS ONLY FEATURES START HERE\n",
    "dataset = pd.read_csv(\"LIWC-results.csv\")\n",
    "dataset = dataset.drop(\"Unnamed: 0\",1)\n",
    "dataset = dataset.drop(\"Unnamed: 0.1\",1)\n",
    "#dataset = dataset.drop(\"text\",1)\n",
    "dataset = dataset.dropna()\n",
    "labels = dataset[\"class\"].values\n",
    "#datapoints = dataset['text'].values\n",
    "labels = labels.astype(\"int\")\n",
    "datapoints = dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val = train_test_split(datapoints,labels,test_size=0.3,shuffle= True, stratify=labels)\n",
    "print(\"len train: \",len(X_train),\"len test: \",len(X_val))\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train['text'].values,tokenizer)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val['text'].values,tokenizer)\n",
    "\n",
    "side_features_train = X_train.drop(['text','class'],axis=1)\n",
    "side_features_val = X_val.drop(['text','class'],axis=1)\n",
    "\n",
    "train_labels = torch.LongTensor(y_train)\n",
    "val_labels = torch.LongTensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clout          29.589001\n",
       "Tone           30.338503\n",
       "Linguistic     68.525904\n",
       "death           0.743717\n",
       "WC            131.966652\n",
       "Cognition      15.436132\n",
       "WPS            20.042821\n",
       "dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_features_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASD\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\ASD\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train:  162439 len test:  69618\n",
      "Tokenizing data...\n",
      "Processed_data : 0\n",
      "Processed_data : 2560\n",
      "Processed_data : 5120\n",
      "Processed_data : 7680\n",
      "Processed_data : 10240\n",
      "Processed_data : 12800\n",
      "Processed_data : 15360\n",
      "Processed_data : 17920\n",
      "Processed_data : 20480\n",
      "Processed_data : 23040\n",
      "Processed_data : 25600\n",
      "Processed_data : 28160\n",
      "Processed_data : 30720\n",
      "Processed_data : 33280\n",
      "Processed_data : 35840\n",
      "Processed_data : 38400\n",
      "Processed_data : 40960\n",
      "Processed_data : 43520\n",
      "Processed_data : 46080\n",
      "Processed_data : 48640\n",
      "Processed_data : 51200\n",
      "Processed_data : 53760\n",
      "Processed_data : 56320\n",
      "Processed_data : 58880\n",
      "Processed_data : 61440\n",
      "Processed_data : 64000\n",
      "Processed_data : 66560\n",
      "Processed_data : 69120\n",
      "Processed_data : 71680\n",
      "Processed_data : 74240\n",
      "Processed_data : 76800\n",
      "Processed_data : 79360\n",
      "Processed_data : 81920\n",
      "Processed_data : 84480\n",
      "Processed_data : 87040\n",
      "Processed_data : 89600\n",
      "Processed_data : 92160\n",
      "Processed_data : 94720\n",
      "Processed_data : 97280\n",
      "Processed_data : 99840\n",
      "Processed_data : 102400\n",
      "Processed_data : 104960\n",
      "Processed_data : 107520\n",
      "Processed_data : 110080\n",
      "Processed_data : 112640\n",
      "Processed_data : 115200\n",
      "Processed_data : 117760\n",
      "Processed_data : 120320\n",
      "Processed_data : 122880\n",
      "Processed_data : 125440\n",
      "Processed_data : 128000\n",
      "Processed_data : 130560\n",
      "Processed_data : 133120\n",
      "Processed_data : 135680\n",
      "Processed_data : 138240\n",
      "Processed_data : 140800\n",
      "Processed_data : 143360\n",
      "Processed_data : 145920\n",
      "Processed_data : 148480\n",
      "Processed_data : 151040\n",
      "Processed_data : 153600\n",
      "Processed_data : 156160\n",
      "Processed_data : 158720\n",
      "Processed_data : 161280\n",
      "Processed_data : 0\n",
      "Processed_data : 2560\n",
      "Processed_data : 5120\n",
      "Processed_data : 7680\n",
      "Processed_data : 10240\n",
      "Processed_data : 12800\n",
      "Processed_data : 15360\n",
      "Processed_data : 17920\n",
      "Processed_data : 20480\n",
      "Processed_data : 23040\n",
      "Processed_data : 25600\n",
      "Processed_data : 28160\n",
      "Processed_data : 30720\n",
      "Processed_data : 33280\n",
      "Processed_data : 35840\n",
      "Processed_data : 38400\n",
      "Processed_data : 40960\n",
      "Processed_data : 43520\n",
      "Processed_data : 46080\n",
      "Processed_data : 48640\n",
      "Processed_data : 51200\n",
      "Processed_data : 53760\n",
      "Processed_data : 56320\n",
      "Processed_data : 58880\n",
      "Processed_data : 61440\n",
      "Processed_data : 64000\n",
      "Processed_data : 66560\n",
      "Processed_data : 69120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASD\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "C:\\Users\\ASD\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:33: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "#CLASSİCAL METHODS ONLY FEATURES START HERE\n",
    "dataset = pd.read_csv(\"LIWC-results.csv\")\n",
    "dataset = dataset.drop(\"Unnamed: 0\",1)\n",
    "dataset = dataset.drop(\"Unnamed: 0.1\",1)\n",
    "#dataset = dataset.drop(\"text\",1)\n",
    "dataset = dataset.dropna()\n",
    "labels = dataset[\"class\"].values\n",
    "#datapoints = dataset['text'].values\n",
    "labels = labels.astype(\"int\")\n",
    "datapoints = dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val = train_test_split(datapoints,labels,test_size=0.3,shuffle= True, stratify=labels)\n",
    "print(\"len train: \",len(X_train),\"len test: \",len(X_val))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "best_bert_model = torch.load('trained_all_side5.pt')\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "config = BertConfig.from_pretrained(model_name, output_hidden_states=False)    \n",
    "bert_model = BertModel.from_pretrained(model_name, config=config)\n",
    "bert_model = bert_model.to(device)\n",
    "bert_model.load_state_dict(best_bert_model.bert.state_dict())\n",
    "bert_model.eval()\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_embeddings = embeddings_from_dataset(X_train['text'].values,tokenizer, bert_model)\n",
    "val_embeddings = embeddings_from_dataset(X_val['text'].values,tokenizer, bert_model)\n",
    "\n",
    "side_features_train = X_train.drop('text',1)\n",
    "side_features_val = X_val.drop('text',1)\n",
    "\n",
    "train_labels = torch.LongTensor(y_train)\n",
    "val_labels = torch.LongTensor(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'train_inputs':train_inputs,'train_masks':train_masks,'train_labels':train_labels,'side_features_train':side_features_train,\\\n",
    "    'val_inputs':val_inputs,'val_masks':val_masks,'val_labels':val_labels,'side_features_val':side_features_val},'processed_dataset_sf.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'train_embeddings':train_embeddings, 'train_labels':train_labels,'side_features_train':side_features_train,\\\n",
    "    'val_embeddings':val_embeddings,'val_labels':val_labels,'side_features_val':side_features_val},'embedding_dataset_sf.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('embedding_dataset_sf.pt')\n",
    "train_embeddings = data['train_embeddings']\n",
    "train_labels = data['train_labels']\n",
    "side_features_train = data['side_features_train']\n",
    "val_embeddings = data['val_embeddings']\n",
    "val_labels = data['val_labels']\n",
    "side_features_val = data['side_features_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('processed_dataset_sf.pt')\n",
    "train_inputs = data['train_inputs']\n",
    "train_masks = data['train_masks']\n",
    "train_labels = data['train_labels']\n",
    "side_features_train = data['side_features_train']\n",
    "val_inputs = data['val_inputs']\n",
    "val_masks = data['val_masks']\n",
    "val_labels = data['val_labels']\n",
    "side_features_val = data['side_features_val']\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 50\n",
    "# Create the DataLoader for our training set\n",
    "train_data = data_utils.TensorDataset(train_inputs, train_masks, train_labels)\n",
    "#train_data = data_utils.TensorDataset(train_inputs, train_masks, torch.Tensor(side_features_train[selected_features].values), train_labels)\n",
    "train_sampler = data_utils.RandomSampler(train_data)\n",
    "train_dataloader = data_utils.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = data_utils.TensorDataset(val_inputs, val_masks, val_labels)\n",
    "#val_data = data_utils.TensorDataset(val_inputs, val_masks, torch.Tensor(side_features_val[selected_features].values), val_labels)\n",
    "val_sampler = data_utils.SequentialSampler(val_data)\n",
    "val_dataloader = data_utils.DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33877   931]\n",
      " [  848 33962]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08282877634850559, 97.44580043072506)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "best_bert_model = torch.load('trained_best_nosf.pt')\n",
    "best_bert_model = best_bert_model.to(device)\n",
    "evaluate(best_bert_model,val_dataloader,use_sf=False,print_cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.440990   |     -      |     -     |   10.86  \n",
      "   1    |   40    |   0.255779   |     -      |     -     |   9.02   \n",
      "   1    |   60    |   0.182657   |     -      |     -     |   9.00   \n",
      "   1    |   80    |   0.230848   |     -      |     -     |   9.28   \n",
      "   1    |   100   |   0.185126   |     -      |     -     |   9.53   \n",
      "   1    |   120   |   0.158856   |     -      |     -     |   9.40   \n",
      "   1    |   140   |   0.146532   |     -      |     -     |   9.47   \n",
      "   1    |   160   |   0.129663   |     -      |     -     |   9.44   \n",
      "   1    |   180   |   0.124825   |     -      |     -     |   9.65   \n",
      "   1    |   200   |   0.138546   |     -      |     -     |   10.24  \n",
      "   1    |   220   |   0.134918   |     -      |     -     |   11.03  \n",
      "   1    |   240   |   0.136362   |     -      |     -     |   11.10  \n",
      "   1    |   260   |   0.111530   |     -      |     -     |   11.05  \n",
      "   1    |   280   |   0.147638   |     -      |     -     |   11.02  \n",
      "   1    |   300   |   0.101914   |     -      |     -     |   11.23  \n",
      "   1    |   320   |   0.139461   |     -      |     -     |   11.11  \n",
      "   1    |   340   |   0.142973   |     -      |     -     |   11.08  \n",
      "   1    |   360   |   0.119502   |     -      |     -     |   11.18  \n",
      "   1    |   380   |   0.107571   |     -      |     -     |   11.20  \n",
      "   1    |   400   |   0.129592   |     -      |     -     |   11.45  \n",
      "   1    |   420   |   0.115948   |     -      |     -     |   11.38  \n",
      "   1    |   440   |   0.096666   |     -      |     -     |   11.37  \n",
      "   1    |   460   |   0.125523   |     -      |     -     |   11.31  \n",
      "   1    |   480   |   0.106753   |     -      |     -     |   11.30  \n",
      "   1    |   500   |   0.120332   |     -      |     -     |   11.26  \n",
      "   1    |   520   |   0.083358   |     -      |     -     |   11.34  \n",
      "   1    |   540   |   0.108409   |     -      |     -     |   11.33  \n",
      "   1    |   560   |   0.094153   |     -      |     -     |   11.42  \n",
      "   1    |   580   |   0.107777   |     -      |     -     |   11.84  \n",
      "   1    |   600   |   0.111052   |     -      |     -     |   11.51  \n",
      "   1    |   620   |   0.113366   |     -      |     -     |   11.39  \n",
      "   1    |   640   |   0.102095   |     -      |     -     |   11.66  \n",
      "   1    |   660   |   0.106066   |     -      |     -     |   11.55  \n",
      "   1    |   680   |   0.083951   |     -      |     -     |   12.06  \n",
      "   1    |   700   |   0.101242   |     -      |     -     |   12.08  \n",
      "   1    |   720   |   0.133630   |     -      |     -     |   13.11  \n",
      "   1    |   740   |   0.129682   |     -      |     -     |   12.84  \n",
      "   1    |   760   |   0.105855   |     -      |     -     |   12.72  \n",
      "   1    |   780   |   0.106610   |     -      |     -     |   12.97  \n",
      "   1    |   800   |   0.090118   |     -      |     -     |   12.53  \n",
      "   1    |   820   |   0.106243   |     -      |     -     |   12.24  \n",
      "   1    |   840   |   0.083320   |     -      |     -     |   12.78  \n",
      "   1    |   860   |   0.095103   |     -      |     -     |   13.54  \n",
      "   1    |   880   |   0.093445   |     -      |     -     |   12.35  \n",
      "   1    |   900   |   0.111313   |     -      |     -     |   14.03  \n",
      "   1    |   920   |   0.128288   |     -      |     -     |   12.78  \n",
      "   1    |   940   |   0.113915   |     -      |     -     |   13.89  \n",
      "   1    |   960   |   0.112653   |     -      |     -     |   12.66  \n",
      "   1    |   980   |   0.095342   |     -      |     -     |   13.40  \n",
      "   1    |  1000   |   0.130373   |     -      |     -     |   13.90  \n",
      "   1    |  1020   |   0.103109   |     -      |     -     |   13.76  \n",
      "   1    |  1040   |   0.110724   |     -      |     -     |   13.48  \n",
      "   1    |  1060   |   0.116599   |     -      |     -     |   12.76  \n",
      "   1    |  1080   |   0.095607   |     -      |     -     |   14.09  \n",
      "   1    |  1100   |   0.110395   |     -      |     -     |   14.10  \n",
      "   1    |  1120   |   0.127734   |     -      |     -     |   13.61  \n",
      "   1    |  1140   |   0.096857   |     -      |     -     |   13.56  \n",
      "   1    |  1160   |   0.124907   |     -      |     -     |   13.56  \n",
      "   1    |  1180   |   0.092560   |     -      |     -     |   15.06  \n",
      "   1    |  1200   |   0.107341   |     -      |     -     |   14.03  \n",
      "   1    |  1220   |   0.086608   |     -      |     -     |   13.60  \n",
      "   1    |  1240   |   0.089674   |     -      |     -     |   14.11  \n",
      "   1    |  1260   |   0.130352   |     -      |     -     |   14.62  \n",
      "   1    |  1280   |   0.088962   |     -      |     -     |   13.41  \n",
      "   1    |  1300   |   0.075456   |     -      |     -     |   13.44  \n",
      "   1    |  1320   |   0.109723   |     -      |     -     |   13.52  \n",
      "   1    |  1340   |   0.097449   |     -      |     -     |   14.70  \n",
      "   1    |  1360   |   0.084885   |     -      |     -     |   14.04  \n",
      "   1    |  1380   |   0.104590   |     -      |     -     |   14.56  \n",
      "   1    |  1400   |   0.092379   |     -      |     -     |   13.36  \n",
      "   1    |  1420   |   0.093039   |     -      |     -     |   13.85  \n",
      "   1    |  1440   |   0.091772   |     -      |     -     |   13.68  \n",
      "   1    |  1460   |   0.086306   |     -      |     -     |   13.90  \n",
      "   1    |  1480   |   0.091800   |     -      |     -     |   13.60  \n",
      "   1    |  1500   |   0.096112   |     -      |     -     |   14.24  \n",
      "   1    |  1520   |   0.085983   |     -      |     -     |   15.25  \n",
      "   1    |  1540   |   0.070189   |     -      |     -     |   14.53  \n",
      "   1    |  1560   |   0.067231   |     -      |     -     |   14.35  \n",
      "   1    |  1580   |   0.094308   |     -      |     -     |   14.68  \n",
      "   1    |  1600   |   0.072286   |     -      |     -     |   13.87  \n",
      "   1    |  1620   |   0.097916   |     -      |     -     |   14.03  \n",
      "   1    |  1640   |   0.071772   |     -      |     -     |   14.88  \n",
      "   1    |  1660   |   0.102325   |     -      |     -     |   14.12  \n",
      "   1    |  1680   |   0.103174   |     -      |     -     |   14.56  \n",
      "   1    |  1700   |   0.071711   |     -      |     -     |   13.93  \n",
      "   1    |  1720   |   0.104870   |     -      |     -     |   14.83  \n",
      "   1    |  1740   |   0.100175   |     -      |     -     |   14.51  \n",
      "   1    |  1760   |   0.088186   |     -      |     -     |   13.81  \n",
      "   1    |  1780   |   0.095836   |     -      |     -     |   14.76  \n",
      "   1    |  1800   |   0.081616   |     -      |     -     |   15.08  \n",
      "   1    |  1820   |   0.073487   |     -      |     -     |   16.48  \n",
      "   1    |  1840   |   0.116593   |     -      |     -     |   14.08  \n",
      "   1    |  1860   |   0.081670   |     -      |     -     |   14.91  \n",
      "   1    |  1880   |   0.097664   |     -      |     -     |   14.43  \n",
      "   1    |  1900   |   0.103613   |     -      |     -     |   15.43  \n",
      "   1    |  1920   |   0.081710   |     -      |     -     |   16.71  \n",
      "   1    |  1940   |   0.097210   |     -      |     -     |   14.01  \n",
      "   1    |  1960   |   0.125858   |     -      |     -     |   13.54  \n",
      "   1    |  1980   |   0.114998   |     -      |     -     |   13.49  \n",
      "   1    |  2000   |   0.082401   |     -      |     -     |   14.19  \n",
      "   1    |  2020   |   0.088559   |     -      |     -     |   14.18  \n",
      "   1    |  2040   |   0.093632   |     -      |     -     |   13.26  \n",
      "   1    |  2060   |   0.090036   |     -      |     -     |   13.74  \n",
      "   1    |  2080   |   0.086389   |     -      |     -     |   12.65  \n",
      "   1    |  2100   |   0.093270   |     -      |     -     |   13.39  \n",
      "   1    |  2120   |   0.112107   |     -      |     -     |   14.02  \n",
      "   1    |  2140   |   0.087608   |     -      |     -     |   12.76  \n",
      "   1    |  2160   |   0.108216   |     -      |     -     |   13.63  \n",
      "   1    |  2180   |   0.086937   |     -      |     -     |   13.50  \n",
      "   1    |  2200   |   0.081774   |     -      |     -     |   13.47  \n",
      "   1    |  2220   |   0.093682   |     -      |     -     |   12.53  \n",
      "   1    |  2240   |   0.077194   |     -      |     -     |   12.98  \n",
      "   1    |  2260   |   0.073521   |     -      |     -     |   13.05  \n",
      "   1    |  2280   |   0.088534   |     -      |     -     |   13.64  \n",
      "   1    |  2300   |   0.067949   |     -      |     -     |   13.38  \n",
      "   1    |  2320   |   0.084402   |     -      |     -     |   13.13  \n",
      "   1    |  2340   |   0.104838   |     -      |     -     |   13.58  \n",
      "   1    |  2360   |   0.080822   |     -      |     -     |   14.39  \n",
      "   1    |  2380   |   0.103991   |     -      |     -     |   12.67  \n",
      "   1    |  2400   |   0.089218   |     -      |     -     |   14.93  \n",
      "   1    |  2420   |   0.075812   |     -      |     -     |   14.54  \n",
      "   1    |  2440   |   0.087330   |     -      |     -     |   15.70  \n",
      "   1    |  2460   |   0.084407   |     -      |     -     |   14.41  \n",
      "   1    |  2480   |   0.082286   |     -      |     -     |   14.52  \n",
      "   1    |  2500   |   0.084317   |     -      |     -     |   15.75  \n",
      "   1    |  2520   |   0.080125   |     -      |     -     |   15.68  \n",
      "   1    |  2540   |   0.086745   |     -      |     -     |   15.65  \n",
      "   1    |  2560   |   0.084615   |     -      |     -     |   13.50  \n",
      "   1    |  2580   |   0.090835   |     -      |     -     |   14.41  \n",
      "   1    |  2600   |   0.099764   |     -      |     -     |   14.78  \n",
      "   1    |  2620   |   0.088196   |     -      |     -     |   13.28  \n",
      "   1    |  2640   |   0.077596   |     -      |     -     |   15.90  \n",
      "   1    |  2660   |   0.099960   |     -      |     -     |   13.07  \n",
      "   1    |  2680   |   0.079192   |     -      |     -     |   14.54  \n",
      "   1    |  2700   |   0.067351   |     -      |     -     |   14.21  \n",
      "   1    |  2720   |   0.053485   |     -      |     -     |   13.91  \n",
      "   1    |  2740   |   0.067593   |     -      |     -     |   14.80  \n",
      "   1    |  2760   |   0.075270   |     -      |     -     |   13.08  \n",
      "   1    |  2780   |   0.112537   |     -      |     -     |   13.51  \n",
      "   1    |  2800   |   0.066695   |     -      |     -     |   16.15  \n",
      "   1    |  2820   |   0.057874   |     -      |     -     |   13.67  \n",
      "   1    |  2840   |   0.079247   |     -      |     -     |   13.75  \n",
      "   1    |  2860   |   0.092202   |     -      |     -     |   14.74  \n",
      "   1    |  2880   |   0.093529   |     -      |     -     |   14.45  \n",
      "   1    |  2900   |   0.086948   |     -      |     -     |   16.66  \n",
      "   1    |  2920   |   0.084126   |     -      |     -     |   14.39  \n",
      "   1    |  2940   |   0.099496   |     -      |     -     |   14.18  \n",
      "   1    |  2960   |   0.049536   |     -      |     -     |   13.95  \n",
      "   1    |  2980   |   0.073581   |     -      |     -     |   14.10  \n",
      "   1    |  3000   |   0.075618   |     -      |     -     |   14.12  \n",
      "   1    |  3020   |   0.075536   |     -      |     -     |   14.23  \n",
      "   1    |  3040   |   0.091445   |     -      |     -     |   14.26  \n",
      "   1    |  3060   |   0.083766   |     -      |     -     |   14.17  \n",
      "   1    |  3080   |   0.102395   |     -      |     -     |   14.13  \n",
      "   1    |  3100   |   0.063158   |     -      |     -     |  1674.58 \n",
      "   1    |  3120   |   0.088606   |     -      |     -     |   18.80  \n",
      "   1    |  3140   |   0.074818   |     -      |     -     |   16.41  \n",
      "   1    |  3160   |   0.066430   |     -      |     -     |   15.28  \n",
      "   1    |  3180   |   0.058494   |     -      |     -     |   15.17  \n",
      "   1    |  3200   |   0.062060   |     -      |     -     |   14.93  \n",
      "   1    |  3220   |   0.078047   |     -      |     -     |   14.44  \n",
      "   1    |  3240   |   0.081248   |     -      |     -     |   14.22  \n",
      "   1    |  3248   |   0.090630   |     -      |     -     |   5.55   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.101439   |  0.077814  |   97.29   |  4058.35 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.052220   |     -      |     -     |   19.63  \n",
      "   2    |   40    |   0.048197   |     -      |     -     |   18.74  \n",
      "   2    |   60    |   0.051915   |     -      |     -     |   18.07  \n",
      "   2    |   80    |   0.031506   |     -      |     -     |   18.17  \n",
      "   2    |   100   |   0.063509   |     -      |     -     |   17.57  \n",
      "   2    |   120   |   0.053872   |     -      |     -     |   16.20  \n",
      "   2    |   140   |   0.043036   |     -      |     -     |   15.96  \n",
      "   2    |   160   |   0.020618   |     -      |     -     |   15.40  \n",
      "   2    |   180   |   0.051272   |     -      |     -     |   16.08  \n",
      "   2    |   200   |   0.034368   |     -      |     -     |   18.44  \n",
      "   2    |   220   |   0.034450   |     -      |     -     |   14.11  \n",
      "   2    |   240   |   0.039965   |     -      |     -     |   14.44  \n",
      "   2    |   260   |   0.051278   |     -      |     -     |   14.43  \n",
      "   2    |   280   |   0.057765   |     -      |     -     |   14.46  \n",
      "   2    |   300   |   0.032874   |     -      |     -     |   16.45  \n",
      "   2    |   320   |   0.031637   |     -      |     -     |   15.98  \n",
      "   2    |   340   |   0.034443   |     -      |     -     |   17.17  \n",
      "   2    |   360   |   0.037194   |     -      |     -     |   15.03  \n",
      "   2    |   380   |   0.030197   |     -      |     -     |   18.21  \n",
      "   2    |   400   |   0.051446   |     -      |     -     |   19.55  \n",
      "   2    |   420   |   0.044548   |     -      |     -     |   15.58  \n",
      "   2    |   440   |   0.055416   |     -      |     -     |   14.90  \n",
      "   2    |   460   |   0.044621   |     -      |     -     |   14.88  \n",
      "   2    |   480   |   0.046641   |     -      |     -     |   14.64  \n",
      "   2    |   500   |   0.037351   |     -      |     -     |   15.59  \n",
      "   2    |   520   |   0.061064   |     -      |     -     |   15.21  \n",
      "   2    |   540   |   0.044736   |     -      |     -     |   14.97  \n",
      "   2    |   560   |   0.045772   |     -      |     -     |   14.92  \n",
      "   2    |   580   |   0.043606   |     -      |     -     |   14.44  \n",
      "   2    |   600   |   0.033186   |     -      |     -     |   14.87  \n",
      "   2    |   620   |   0.035672   |     -      |     -     |   14.17  \n",
      "   2    |   640   |   0.042398   |     -      |     -     |   14.61  \n",
      "   2    |   660   |   0.038071   |     -      |     -     |   13.82  \n",
      "   2    |   680   |   0.026422   |     -      |     -     |   14.53  \n",
      "   2    |   700   |   0.054932   |     -      |     -     |   14.71  \n",
      "   2    |   720   |   0.043412   |     -      |     -     |   14.22  \n",
      "   2    |   740   |   0.052353   |     -      |     -     |   14.85  \n",
      "   2    |   760   |   0.027672   |     -      |     -     |   14.52  \n",
      "   2    |   780   |   0.049397   |     -      |     -     |   14.76  \n",
      "   2    |   800   |   0.033620   |     -      |     -     |   14.40  \n",
      "   2    |   820   |   0.061513   |     -      |     -     |   14.28  \n",
      "   2    |   840   |   0.044058   |     -      |     -     |   14.99  \n",
      "   2    |   860   |   0.037896   |     -      |     -     |   14.78  \n",
      "   2    |   880   |   0.043229   |     -      |     -     |   14.65  \n",
      "   2    |   900   |   0.034503   |     -      |     -     |   13.86  \n",
      "   2    |   920   |   0.061612   |     -      |     -     |   13.94  \n",
      "   2    |   940   |   0.041226   |     -      |     -     |   14.33  \n",
      "   2    |   960   |   0.036961   |     -      |     -     |   14.64  \n",
      "   2    |   980   |   0.051622   |     -      |     -     |   14.30  \n",
      "   2    |  1000   |   0.037790   |     -      |     -     |   13.44  \n",
      "   2    |  1020   |   0.041826   |     -      |     -     |   13.75  \n",
      "   2    |  1040   |   0.050992   |     -      |     -     |   13.63  \n",
      "   2    |  1060   |   0.047012   |     -      |     -     |   13.58  \n",
      "   2    |  1080   |   0.044617   |     -      |     -     |   14.42  \n",
      "   2    |  1100   |   0.047561   |     -      |     -     |   14.39  \n",
      "   2    |  1120   |   0.045782   |     -      |     -     |   14.42  \n",
      "   2    |  1140   |   0.050687   |     -      |     -     |   14.21  \n",
      "   2    |  1160   |   0.033666   |     -      |     -     |   17.29  \n",
      "   2    |  1180   |   0.040889   |     -      |     -     |   14.14  \n",
      "   2    |  1200   |   0.042647   |     -      |     -     |   13.68  \n",
      "   2    |  1220   |   0.029754   |     -      |     -     |   15.32  \n",
      "   2    |  1240   |   0.051075   |     -      |     -     |   15.56  \n",
      "   2    |  1260   |   0.039034   |     -      |     -     |   14.45  \n",
      "   2    |  1280   |   0.042859   |     -      |     -     |   14.30  \n",
      "   2    |  1300   |   0.035248   |     -      |     -     |   13.58  \n",
      "   2    |  1320   |   0.022472   |     -      |     -     |   14.28  \n",
      "   2    |  1340   |   0.037535   |     -      |     -     |   13.98  \n",
      "   2    |  1360   |   0.039749   |     -      |     -     |   14.68  \n",
      "   2    |  1380   |   0.039030   |     -      |     -     |   14.48  \n",
      "   2    |  1400   |   0.050013   |     -      |     -     |   15.13  \n",
      "   2    |  1420   |   0.038493   |     -      |     -     |   14.03  \n",
      "   2    |  1440   |   0.045316   |     -      |     -     |   13.73  \n",
      "   2    |  1460   |   0.025554   |     -      |     -     |   13.76  \n",
      "   2    |  1480   |   0.037936   |     -      |     -     |   14.01  \n",
      "   2    |  1500   |   0.044468   |     -      |     -     |   13.72  \n",
      "   2    |  1520   |   0.018667   |     -      |     -     |   13.91  \n",
      "   2    |  1540   |   0.046071   |     -      |     -     |   14.75  \n",
      "   2    |  1560   |   0.029402   |     -      |     -     |   15.00  \n",
      "   2    |  1580   |   0.039907   |     -      |     -     |   15.14  \n",
      "   2    |  1600   |   0.025579   |     -      |     -     |   14.38  \n",
      "   2    |  1620   |   0.039480   |     -      |     -     |   13.88  \n",
      "   2    |  1640   |   0.061213   |     -      |     -     |   13.64  \n",
      "   2    |  1660   |   0.051578   |     -      |     -     |   13.76  \n",
      "   2    |  1680   |   0.023046   |     -      |     -     |   13.99  \n",
      "   2    |  1700   |   0.036069   |     -      |     -     |   14.36  \n",
      "   2    |  1720   |   0.042516   |     -      |     -     |   15.05  \n",
      "   2    |  1740   |   0.028723   |     -      |     -     |   16.07  \n",
      "   2    |  1760   |   0.024296   |     -      |     -     |   14.21  \n",
      "   2    |  1780   |   0.042676   |     -      |     -     |   14.24  \n",
      "   2    |  1800   |   0.032134   |     -      |     -     |   14.92  \n",
      "   2    |  1820   |   0.022095   |     -      |     -     |   14.96  \n",
      "   2    |  1840   |   0.023940   |     -      |     -     |   15.15  \n",
      "   2    |  1860   |   0.082162   |     -      |     -     |   14.94  \n",
      "   2    |  1880   |   0.035797   |     -      |     -     |   13.99  \n",
      "   2    |  1900   |   0.024014   |     -      |     -     |   14.02  \n",
      "   2    |  1920   |   0.064723   |     -      |     -     |   15.44  \n",
      "   2    |  1940   |   0.052447   |     -      |     -     |   16.10  \n",
      "   2    |  1960   |   0.040332   |     -      |     -     |   17.37  \n",
      "   2    |  1980   |   0.043923   |     -      |     -     |   17.26  \n",
      "   2    |  2000   |   0.030493   |     -      |     -     |   15.50  \n",
      "   2    |  2020   |   0.034147   |     -      |     -     |   14.53  \n",
      "   2    |  2040   |   0.034083   |     -      |     -     |   14.75  \n",
      "   2    |  2060   |   0.031355   |     -      |     -     |   15.03  \n",
      "   2    |  2080   |   0.058766   |     -      |     -     |   15.28  \n",
      "   2    |  2100   |   0.046108   |     -      |     -     |   15.41  \n",
      "   2    |  2120   |   0.043825   |     -      |     -     |   13.80  \n",
      "   2    |  2140   |   0.031442   |     -      |     -     |   13.79  \n",
      "   2    |  2160   |   0.025388   |     -      |     -     |   13.77  \n",
      "   2    |  2180   |   0.052538   |     -      |     -     |   14.07  \n",
      "   2    |  2200   |   0.044517   |     -      |     -     |   13.75  \n",
      "   2    |  2220   |   0.033953   |     -      |     -     |   14.80  \n",
      "   2    |  2240   |   0.035788   |     -      |     -     |   13.81  \n",
      "   2    |  2260   |   0.025778   |     -      |     -     |   13.77  \n",
      "   2    |  2280   |   0.061685   |     -      |     -     |   14.08  \n",
      "   2    |  2300   |   0.037152   |     -      |     -     |   14.11  \n",
      "   2    |  2320   |   0.018149   |     -      |     -     |   19.57  \n",
      "   2    |  2340   |   0.029418   |     -      |     -     |   15.11  \n",
      "   2    |  2360   |   0.052545   |     -      |     -     |   15.12  \n",
      "   2    |  2380   |   0.033428   |     -      |     -     |   15.27  \n",
      "   2    |  2400   |   0.042711   |     -      |     -     |   14.91  \n",
      "   2    |  2420   |   0.032575   |     -      |     -     |   14.14  \n",
      "   2    |  2440   |   0.034735   |     -      |     -     |   13.84  \n",
      "   2    |  2460   |   0.026243   |     -      |     -     |   15.04  \n",
      "   2    |  2480   |   0.046940   |     -      |     -     |   14.04  \n",
      "   2    |  2500   |   0.026430   |     -      |     -     |   14.89  \n",
      "   2    |  2520   |   0.032416   |     -      |     -     |   15.97  \n",
      "   2    |  2540   |   0.042840   |     -      |     -     |   15.06  \n",
      "   2    |  2560   |   0.022242   |     -      |     -     |   14.98  \n",
      "   2    |  2580   |   0.031429   |     -      |     -     |   14.31  \n",
      "   2    |  2600   |   0.013948   |     -      |     -     |   14.02  \n",
      "   2    |  2620   |   0.046014   |     -      |     -     |   14.20  \n",
      "   2    |  2640   |   0.026242   |     -      |     -     |   14.79  \n",
      "   2    |  2660   |   0.043055   |     -      |     -     |   14.70  \n",
      "   2    |  2680   |   0.049468   |     -      |     -     |   14.46  \n",
      "   2    |  2700   |   0.037757   |     -      |     -     |   15.96  \n",
      "   2    |  2720   |   0.025571   |     -      |     -     |   15.65  \n",
      "   2    |  2740   |   0.047551   |     -      |     -     |   16.00  \n",
      "   2    |  2760   |   0.044772   |     -      |     -     |   15.36  \n",
      "   2    |  2780   |   0.033805   |     -      |     -     |   14.88  \n",
      "   2    |  2800   |   0.017520   |     -      |     -     |   15.38  \n",
      "   2    |  2820   |   0.028596   |     -      |     -     |   13.94  \n",
      "   2    |  2840   |   0.033611   |     -      |     -     |   14.48  \n",
      "   2    |  2860   |   0.085072   |     -      |     -     |   16.78  \n",
      "   2    |  2880   |   0.057318   |     -      |     -     |   14.65  \n",
      "   2    |  2900   |   0.027315   |     -      |     -     |   13.70  \n",
      "   2    |  2920   |   0.028328   |     -      |     -     |   14.09  \n",
      "   2    |  2940   |   0.035088   |     -      |     -     |   14.03  \n",
      "   2    |  2960   |   0.036172   |     -      |     -     |   13.69  \n",
      "   2    |  2980   |   0.069928   |     -      |     -     |   14.08  \n",
      "   2    |  3000   |   0.039870   |     -      |     -     |   13.70  \n",
      "   2    |  3020   |   0.034460   |     -      |     -     |   13.74  \n",
      "   2    |  3040   |   0.045776   |     -      |     -     |   13.61  \n",
      "   2    |  3060   |   0.044267   |     -      |     -     |   14.79  \n",
      "   2    |  3080   |   0.036742   |     -      |     -     |   14.18  \n",
      "   2    |  3100   |   0.055888   |     -      |     -     |   14.56  \n",
      "   2    |  3120   |   0.044412   |     -      |     -     |   14.44  \n",
      "   2    |  3140   |   0.039866   |     -      |     -     |   14.69  \n",
      "   2    |  3160   |   0.032272   |     -      |     -     |   14.34  \n",
      "   2    |  3180   |   0.039834   |     -      |     -     |   14.37  \n",
      "   2    |  3200   |   0.028646   |     -      |     -     |   13.67  \n",
      "   2    |  3220   |   0.044153   |     -      |     -     |   14.75  \n",
      "   2    |  3240   |   0.029541   |     -      |     -     |   14.13  \n",
      "   2    |  3248   |   0.020663   |     -      |     -     |   5.87   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.040203   |  0.082829  |   97.45   |  2643.02 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "#best_trained = torch.load('trained_all_sideselected.pt')\n",
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2,len_train=len(train_dataloader),  freeze_bert=False, pretrained_model=None, side_feature_size=0)#len(selected_features))\n",
    "#bert_classifier.bert.load_state_dict(best_trained.bert.state_dict())\n",
    "train(bert_classifier, train_dataloader, optimizer, scheduler, val_dataloader, epochs=2, evaluation=True, use_sf=False)#True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_classifier.projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bert_classifier, 'trained_best_nosf.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bert_classifier,'trained_all_t.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'train_inputs':train_inputs,'train_masks':train_masks,'train_labels':train_labels, 'val_inputs':val_inputs,'val_masks':val_masks,'val_labels':val_labels},'processed_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASD\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "corpus_reddit = pd.read_csv('reddit_corpus_agree.csv')\n",
    "corpus_reddit['label'] = 0\n",
    "corpus_reddit['label'].loc[(corpus_reddit['cls']=='Risk')] = 1 \n",
    "del corpus_reddit['cls']\n",
    "\n",
    "batch_size = 1\n",
    "texts, labels =  corpus_reddit['text'], corpus_reddit['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "test_inputs, test_masks = preprocessing_for_bert(texts,tokenizer,max_len=512)\n",
    "test_labels = torch.LongTensor(labels)\n",
    "\n",
    "test_data = data_utils.TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = data_utils.SequentialSampler(test_data)\n",
    "test_dataloader = data_utils.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_without_sf = torch.load('trained_best_nosf.pt')\n",
    "#best_without_sf.bert.load_state_dict(bert_classifier.bert.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5  15]\n",
      " [ 10 141]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5187441080708903, 85.38011695906432)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(best_without_sf, test_dataloader, use_sf=False, print_cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] the biggest lie i have ever been told was that you should treat others the way you ’ d want to be treated. people will treat you like shit regardless. you can give your best to people and they will still treat you how they want to. i am done trying to be good to people who aren ’ t good to me. the funny part is after it ’ s all said and done, you will still feel like the bad guy even though you weren ’ t in that situation. i just don ’ t care enough to live in a world that doesn ’ t care about me. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] i feel lost from trying to help people on suicidewatch i ended up being one of the ones that need help. how ironic, am i right? it just feels so unfair... i, a person that never did anything right and never really clinged to life, gets to live while many, many good people have to die. i don't like it, that's unfair. i wish i could offer each of them a year of my existence. i want to see them enjoy the warm sunlight on their skin, pet a dog again, eat some ice cream. meanwhile i am here, feeling like my heart is being torn apart, like my body is always cold and frail and unable to cry even though i know i need to. i feel so lost and lonely. i keep thinking about suicide and how many people i would disappoint by doing that... i just want to feel alive or offer my life to who really needs it. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] my sister's suicide this week. i ’ ve never posted here before, but i thought i ’ d share my story due to events that happened this week. i am sophia ’ s younger brother ( i have two older sisters, as well ), and i am devastated by her suicide at her accommodation near the university she studied at. this is her reddit account which she made this month : ( [ https : / / www. reddit. com / user / humanzucchini ] ( https : / / www. reddit. com / user / humanzucchini ) ). i was not aware of how her thoughts had changed since i last met her in september 2018, and it ’ s unfortunate that i was not given the chance to contact her, as i have autism and depression too. i had no idea that she tried to run away before i contacted her on her birthday this month ; she actually responded “ thank you, love you always! ”, just two weeks ago from today. & # x200b ; we had our fights and arguments in the past, but we sincerely amended this last year, and we enjoyed our older sister ’ s wedding together ( when we went abroad in august 2018 ). i genuinely believed she would come home for the easter holidays in a few weeks, as i accepted that she didn ’ t want to come home for christmas due to wanting to excel in her studies. this tragedy has brought the family closer together : i had a heart - to - heart with my father, who i thought didn ’ t understand my emotions or cared enough about them ; i vowed to stop being so shy and reclusive around family ; i promised that if i ever felt like this, i would get in - touch immediately ; i contacted my old friends from school and have planned to meet them again. i have been taken aback by all the supportive comments i received, even from people i never really spoke to that i assumed didn ’ t care for me. & # x200b ; she was proud of me, because, last year, on the drive back home from the airport, she told me i had overcome so much, in regard to all my troubles and suicidal behaviour since 2015. i don ’ t want the same fate as her, because i feel responsible for this world, regardless of how much evil is committed every day, and i want to change it for the better in my life. aside from the times that we fell - out, i tried to socialise with her, as she [SEP]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1])\n",
      "[CLS] holy shit dude i remember thinking how bizarre the idea of suicide was back when i was a kid and now im here longing it more than ever : / for me being suicidal feels too normal now if im not suicidal i find ways to make myself fall back again this is plain awful [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] my mom attempted suicide today tw : kind of graphic description of suicide attempt so at around midnight on 5 / 31 / 18 i woke up to my brother coming into my room and screaming that our mom tried to kill herself and that she wasn ’ t breathing. i immediately got up and went outside, i went into the backyard and into the garage, where my step father was trying really hard to give her cpr. she tried to kill herself by hanging, she took an electrical cord and draped it over a hook on the ceiling, and wrapped it around her neck. thankfully because of how poor her attempt was, she wasn ’ t fully hanging off of the ground, and was mostly on the ground. we don ’ t know how long she was out there and we don ’ t know how long her airway had been cut off. anyway, as soon as my step father got her to start gasping for breath, the paramedics showed up and put an oxygen mask on her. they took her away into the ambulance and my brother, me, and my step father got ready to go to the hospital. eventually we ended up in the er waiting for answers about my mom. they had first told us that she might have suffered significant brain damage and could end up brain dead. however, they took her to get a ct scan of her brain, and they then told us that they don ’ t see any significant damage to the brain, no swelling or bleeding, and her neck was not injured significantly. i ’ m so thankful that the damage that was done wasn ’ t worse. after the horrifying news we decided to wait to see her, talk to her a little, and then go home. when we were able to go see her i went in first. she was breathing so hard and she was in a coma. i don ’ t know how long her brain went without oxygen and i just really hope that she wakes up and can make even somewhat of a recovery. all we know as of right now ( 5 : 00 am on 5 / 31 / 18 ) is that she is stable but in critical condition, and now we ’ re just waiting for her to wake up. i have a lot of thoughts going on in my head right now but mostly i just want her to wake up and not be a vegetable. the only thing i ’ m really worried about is the fact that she was drinking so much alcohol when she did it, and with her asthma and obesity she ’ s more at risk of complications.. you really [SEP]\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1])\n",
      "[CLS] everyone wants me get help so i don't kill myself but nobody wants to talk to me and help me by just talking to me [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] everyone wants you to do something, but noone wants to help you in person. that's how it is. it's all a lie, all pretending, all fake. & # x200b ; if you'll ever go to a psychiatrist... if you'll ever go to a therapist... if you'll ever go to a psychologist... or even if you ever come across some random on the internet, or in real life... & # x200b ; they are all smart asses, all knowing, but not even one of them will ever give you a hand. it's like coaching. giving worthless advice. & # x200b ; poor? get a job. sad? find happiness. lonely? meet people. & # x200b ; wow, really? wow, thank you so much, i didn't know it's that simple! wow! thank you my savior. i'll be rich now, happy, and have plenty of friends. i was so stupid, thank you for showing me the way. & # x200b ; that's the point, that's the key. 32 fucking years, and you dare to say me, do something?! & # x200b ; \" a drowning man will clutch at a straw \", but you first need to give them one. a lot of people could be saved if they had anyone by their side, cut the bullshit, and chit chat. if you're not here with me, then just fuck off. i don't need no imaginary fake friends. i wouldn't mind friends with benefits though, at least there would be benefits, obviously. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] will someone read this? no. no one will. no one cares about me. why am i still typing? goodbye world edit : i post on this sub when i ’ m really lonely. i ’ m thankful that people did read this. i really am. i was saying that because i know that us usually other people ’ s posts go unanswered. it really sucks and i was worried the same would happen to me. i do my best to respond to other people ’ s posts that don ’ t have any responses. thank you guys so much for responding. thank you guys so much. it means so much to me. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1])\n",
      "[CLS] i wish i could give someone else my life some people are fighting to live, they are fighting death every day, it amaze me, wish i can appreciate being able to live but instead i wish to die as soon as possible [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] update thank you, everyone, [UNK] who pushed me to live!!!!!!! thank you everyone who helped!!!!!!!! so after posting this 28 days ago i wrote my best friend who's out of state a suicide note and i closed my phone and social media and popped some pills and right then there was a knock at my door and it was the cops they took me to a psychiatric ward were i spent a few days a little over a week it felt like a month but i swear i meet some amazing people and my family and friends visited every day and now i'm on my medication and things are turning around a lot!!!!!! i'm moving out to my best friend and taking a semester off to recoup from school i explained to my friend about the 1k and she wasn't sweating it she said my life was more important but long story short everything worked out i love you strangers and thank you for helping me \\ ^ \\ _ \\ ^! xoxoxox [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] why does everyone think therapy is some miracle cure??? cbt is literally a psychologist or psychiatrist or therapist or fucking whatever telling you things you already damn know and don ’ t have the motivation or energy to execute. “ think positive ”, “ focus on breathing ”, “ exercise ”, “ find time to do things you enjoy ”. i could pull this shit out of my ass. i fucking hate it when people tell me to “ get help ”. there is no fucking help. only i can help myself, and i can ’ t. edit : the comments saying you only get what you put in, i ’ m done, i have nothing to put in. that ’ s kinda what depression does [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] do y ’ all ’ s ever want to kill yourself over a minor inconvenience and that makes you want to kill yourself even more cause other people have it way worse? like, i ’ m reading posts on this sub where people ’ s siblings / loved ones have killed themselves and they want to follow, that one guy was a pedophile, people are extremely lonely / ugly / poor / abused, and it ’ s just an overall shit show. i dropped like 5 dishes at work today and that was enough to almost make me go over the edge. there are literally slaves that have known nothing but agony their entire lives in this world and i ’ m just your average clumsy 18 year old who, in the grand scheme of things, has nothing to be worried about. fuck. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] anybody else wishing that they could run away instead of killing themselves? i wish i had some money saved away and a car, i wish i could drive away and never come back to my life. i always wish for a simple life, i always dream i ’ m driving to uruguay and that i ’ m changing my name to hermano or whatever the fuck, i ’ d teach kids to swim and spend my days getting stoned by myself. i ’ d volunteer at a soup kitchen and write my books at night. but that never happens, i ’ m completely by myself and in a relationship where i ’ m most likely being used. nobody gives a fuck about me. i just want to be better. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] “ it gets better ” no it fucking doesn ’ t you cunt i ’ m so sick of people telling me that it gets better, all it does is give me false hope, i ’ ve been waiting for things to get better since i was a kid, it does not get better. it doesn ’ t fucking get better stop saying that bullshit those words are so dangerous because all you do is set yourself / the other person up for disappointment. my pain has been never ending. stop saying i ’ m going to get better because i haven ’ t. my mom just came in my room and lectured and shamed me for not doing anything with my life and having no friends, like yeah no shit? it ’ s called having depression you dumb fuck edit : my anger doesn ’ t come from the fact that people are trying to give me hope, that is not the purpose of this post, the purpose of this post isn ’ t to spread the message that “ it never gets better ” because it definitely can and has for many people. the issue is when people use the stupid phrase “ it gets better ” as if it as definite event that is 100 % going to occur, and it is highly offensive to me because i believed that as a kid, i believed that things just had to get better, but they haven ’ t. i ’ m aware that things can get better, just like things can get worse, but it ’ s not going to 100 % get better because no one can really dictate that unless you can see into the future. saying that shit just sets people up for disappointment, it ’ s a statement based on delusions and false hope. there are some people who will die depressed, there are some people who will die in pain, people whose illnesses will kill them, and to say that it gets better, as if depression is simply a phase or passing mood, is extremely invalidating and minimizes the severity of the illness. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] i ’ m more afraid to live another 60 years than dying. does anyone else feel this way? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0])\n",
      "[CLS] new wiki on how to avoid accidentally encouraging suicide, and how to spot covert incitement we've been seeing a worrying increase in pro - suicide content showing up here and, and also going unreported. this undermines our purpose here, so we wanted to highlight and clarify our guidelines about both direct and indirect incitement of suicide. we've created a wiki that covers these issues. we hope this will be helpful to anyone who's wondering whether something's okay here and which responses to report. it explains in detail why * any * validation of suicidal intent, even an \" innocent \" message like \" if you're 100 % committed, i'll just wish you peace \" is likely to increase people's pain, and why it's important to report even subtle pro - suicide comments. the full text of the wiki's current version is below, and it is maintained at [ / r / suicidewatch / wiki / incitement ] ( http : / / www. reddit. com / r / suicidewatch / wiki / incitement ). we deeply appreciate everyone who gives responsive, empathetic, non - judgemental support to our ops, and we particularly thank everyone who's already been reporting incitement in all forms. please report any post or comment that encourages suicide ( or that breaks any of the other guidelines in the sidebar ) to the moderators, either by clicking the \" report \" button or by [ sending us a modmail ] ( https : / / www. reddit. com / message / compose? to = % 2fr % 2fsuicidewatch ) with a link. we deal with all guideline violations that are reported to us as soon as we can, but we can't read everything so community reports are essential. if you get a pm that breaks the guidelines, please report it both [ to the reddit sitewide admins ] ( http : / / www. reddit. com / report ) and to us in modmail. thanks to all the great citizens of the community who help flag problem content and behaviour for us. * * * * * * * * * [ / r / suicidewatch / wiki / incitement ] ( http : / / www. reddit. com / r / suicidewatch / wiki / incitement ) * * * * * * * * * * # # # summary # # # * * it's important to respect [SEP]\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1])\n",
      "[CLS] i hate how people dismiss us when we openly say that we are suicidal but when someone keep quiet and kill them selves people be shocked like “ they never said anything i didn ’ t know ” wake tf up and love me stop dismissing how i feel my parents kicked me out for being suicidal, now a family friend killed himself and they are all suffering not knowing why because he was relatively “ happy ” and had a good life... meanwhile my mother while i was panicking she handed me a knife. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1])\n",
      "[CLS] please kill me in my sleep please kill me in my sleep please kill me in my sleep please kill me in my sleep thanks [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1])\n",
      "[CLS] 757 ppl online its comforting to know that theres ppl other than me who feel this way but why am i still so lonely in this feeling. idk if that even made sense but tbh i really just dont want to exist. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0])\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    false_p = 0\n",
    "    for data,mask, label in test_dataloader:\n",
    "        logit = best_without_sf(data.to(device), mask.to(device))\n",
    "        pred = torch.argmax(logit, dim=1).flatten()\n",
    "\n",
    "        if pred.cpu() != label:\n",
    "            false_p+=1\n",
    "            print(f'prediction: {pred}')\n",
    "            print(f'true_value: {label}')\n",
    "            print(tokenizer.decode(data.cpu()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_liwc_dataset(max_len=512, use_bert=True,use_sf =True):\n",
    "    dataset = pd.read_csv(\"test_LIWC.csv\")\n",
    "\n",
    "    dataset = dataset.dropna()\n",
    "    labels = dataset[\"cls\"].values\n",
    "    #datapoints = dataset['text'].values\n",
    "    labels = labels.astype(\"int\")\n",
    "    side_features = dataset[selected_features]\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "    test_inputs, test_masks = preprocessing_for_bert(dataset['text'],tokenizer,max_len=max_len)\n",
    "    test_labels = torch.LongTensor(labels)\n",
    "    batch_size = 64\n",
    "    if use_bert:\n",
    "        if use_sf:\n",
    "            test_data = data_utils.TensorDataset(test_inputs, test_masks, torch.Tensor(side_features.values), test_labels)\n",
    "        else:\n",
    "            test_data = data_utils.TensorDataset(test_inputs, test_masks, test_labels)\n",
    "    else:\n",
    "        if use_sf:\n",
    "            test_data = data_utils.TensorDataset(torch.Tensor(side_features.values), test_labels)\n",
    "\n",
    "    test_sampler = data_utils.SequentialSampler(test_data)\n",
    "    test_dataloader = data_utils.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "    \n",
    "    return test_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 44  62]\n",
      " [ 21 267]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7693839584078107, 79.0625)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#best_bert_model = bert_classifier\n",
    "#sf_bert_model = torch.load('trained_all_side5.pt')\n",
    "#best_bert_model.bert.load_state_dict(sf_bert_model.bert.state_dict())\n",
    "#bert_model_5 = torch.load('trained_all_best.pt')\n",
    "#classifier_nn = torch.load('classifier.pt')\n",
    "best_bert_model = torch.load('trained_best_nosf.pt')\n",
    "#best_bert_model = BertClassifier(len(selected_features),freeze_bert=True)\n",
    "#best_bert_model.bert.load_state_dict(bert_model_5.bert.state_dict())\n",
    "#best_bert_model.classifier.load_state_dict(classifier_nn.classifier.state_dict())\n",
    "best_bert_model = best_bert_model.to(device)\n",
    "\n",
    "test_dataloader = create_test_liwc_dataset(use_sf=False)\n",
    "evaluate(best_bert_model, test_dataloader, use_sf=False, print_cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7893401015228426"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(44+267)/(62+21+44+267)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kaggle_test_liwc_dataset(max_len= 512, use_bert=True,use_sf =True):\n",
    "    dataset = pd.read_csv(\"kaggle_test_LIWC.csv\")\n",
    "    dataset = dataset.dropna()\n",
    "    labels = dataset[\"cls\"].values\n",
    "    labels = labels.astype(\"int\")\n",
    "    side_features = dataset[selected_features]\n",
    "\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "    test_inputs, test_masks = preprocessing_for_bert(dataset['text'],tokenizer,max_len=max_len)\n",
    "    test_labels = torch.LongTensor(labels)\n",
    "    batch_size = 16\n",
    "    if use_bert:\n",
    "        if use_sf:\n",
    "            test_data = data_utils.TensorDataset(test_inputs, test_masks, torch.Tensor(side_features.values), test_labels)\n",
    "        else:\n",
    "            test_data = data_utils.TensorDataset(test_inputs, test_masks, test_labels)\n",
    "    else:\n",
    "        if use_sf:\n",
    "            test_data = data_utils.TensorDataset(torch.Tensor(side_features.values), test_labels)\n",
    "\n",
    "    test_sampler = data_utils.SequentialSampler(test_data)\n",
    "    test_dataloader = data_utils.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0]\n",
      " [ 65 400]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.502343829597036, 86.45833333333333)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#bert_model_5 = torch.load('trained_all_side5.pt')\n",
    "#classifier_nn = torch.load('classifier.pt')\n",
    "best_bert_model = torch.load('trained_best_nosf.pt')\n",
    "#best_bert_model = BertClassifier(len(selected_features),freeze_bert=True)\n",
    "#best_bert_model.bert.load_state_dict(bert_model_5.bert.state_dict())\n",
    "#best_bert_model.classifier.load_state_dict(classifier_nn.classifier.state_dict())\n",
    "#best_bert_model = best_bert_model.to(device)\n",
    "#best_bert_model = bert_classifier\n",
    "#sf_bert_model = torch.load('trained_all_side5.pt')\n",
    "#best_bert_model.bert.load_state_dict(sf_bert_model.bert.state_dict())\n",
    "test_dataloader = create_kaggle_test_liwc_dataset(use_sf=False)\n",
    "evaluate(best_bert_model, test_dataloader, use_sf=False, print_cm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('embedding_dataset_sf.pt')\n",
    "train_embeddings = data['train_embeddings']\n",
    "train_labels = data['train_labels']\n",
    "side_features_train = data['side_features_train']\n",
    "val_embeddings = data['val_embeddings']\n",
    "val_labels = data['val_labels']\n",
    "side_features_val = data['side_features_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 8.901910854611747e-05, train_accuracy: 0.9853606584625614\n",
      "test_loss: 2.0104463120501908e-05, test_accuracy: 0.9880490677698296\n",
      "Epoch 2, train_loss: 7.162634903195969e-05, train_accuracy: 0.9881740222483517\n",
      "test_loss: 1.8321761562373632e-05, test_accuracy: 0.9882070728834497\n",
      "Epoch 3, train_loss: 7.300922849311526e-05, train_accuracy: 0.9883156138612033\n",
      "test_loss: 1.8408531802261347e-05, test_accuracy: 0.9884081703007843\n",
      "Epoch 4, train_loss: 7.093625224824985e-05, train_accuracy: 0.9885002985736184\n",
      "test_loss: 1.794350969724289e-05, test_accuracy: 0.9885374472119279\n",
      "Epoch 5, train_loss: 7.124680682589939e-05, train_accuracy: 0.9883710192749278\n",
      "test_loss: 1.7789146425235396e-05, test_accuracy: 0.9884368985032607\n",
      "Epoch 6, train_loss: 6.91454859359425e-05, train_accuracy: 0.9886480463435505\n",
      "test_loss: 1.7962717191923825e-05, test_accuracy: 0.9885805395156425\n",
      "Epoch 7, train_loss: 6.830159199830682e-05, train_accuracy: 0.9889189172550927\n",
      "test_loss: 1.7898568493500596e-05, test_accuracy: 0.9886236318193571\n",
      "Epoch 8, train_loss: 6.871675309172071e-05, train_accuracy: 0.9887527010139191\n",
      "test_loss: 1.7653241314364438e-05, test_accuracy: 0.9888965497428825\n",
      "Epoch 9, train_loss: 6.818178614034244e-05, train_accuracy: 0.9888511995272071\n",
      "test_loss: 1.81668365912041e-05, test_accuracy: 0.988465626705737\n",
      "Epoch 10, train_loss: 6.764944738781727e-05, train_accuracy: 0.9890174157683808\n",
      "test_loss: 1.7282686472194225e-05, test_accuracy: 0.9889970984515499\n",
      "Epoch 11, train_loss: 6.752911549046652e-05, train_accuracy: 0.9890297280825417\n",
      "test_loss: 1.7837928287799858e-05, test_accuracy: 0.988695452325548\n",
      "Epoch 12, train_loss: 6.733643574661793e-05, train_accuracy: 0.9891097581245883\n",
      "test_loss: 1.7365383791164617e-05, test_accuracy: 0.9888821856416444\n",
      "Epoch 13, train_loss: 6.623343784851684e-05, train_accuracy: 0.9891159142816688\n",
      "test_loss: 1.7065108687147037e-05, test_accuracy: 0.9888821856416444\n",
      "Epoch 14, train_loss: 6.636494935778563e-05, train_accuracy: 0.9890728211821053\n",
      "test_loss: 1.6980038099587023e-05, test_accuracy: 0.9891120112614554\n",
      "Epoch 15, train_loss: 6.583976087777164e-05, train_accuracy: 0.9892021004807958\n",
      "test_loss: 1.733034589962265e-05, test_accuracy: 0.988695452325548\n",
      "Epoch 16, train_loss: 6.679894793363677e-05, train_accuracy: 0.9892575058945204\n",
      "test_loss: 1.7553399114402737e-05, test_accuracy: 0.9887529087305007\n",
      "Epoch 17, train_loss: 6.665034902386482e-05, train_accuracy: 0.9890974458104272\n",
      "test_loss: 1.734361199559831e-05, test_accuracy: 0.9889540061478354\n",
      "Epoch 18, train_loss: 6.536459872878119e-05, train_accuracy: 0.9892144127949569\n",
      "test_loss: 1.704950694042599e-05, test_accuracy: 0.9887241805280244\n",
      "Epoch 19, train_loss: 6.531262830151505e-05, train_accuracy: 0.9893683167219695\n",
      "test_loss: 1.7473758098122554e-05, test_accuracy: 0.989011462552788\n",
      "Epoch 20, train_loss: 6.47694324934923e-05, train_accuracy: 0.9892944428370034\n",
      "test_loss: 1.7333869321759846e-05, test_accuracy: 0.9889827343503117\n",
      "Epoch 21, train_loss: 6.459852115563437e-05, train_accuracy: 0.9893190674653255\n",
      "test_loss: 1.7369404084557328e-05, test_accuracy: 0.9887960010342153\n",
      "Epoch 22, train_loss: 6.415144874905803e-05, train_accuracy: 0.9894298782927745\n",
      "test_loss: 1.8615596871382682e-05, test_accuracy: 0.9888390933379299\n",
      "Epoch 23, train_loss: 6.436757736054302e-05, train_accuracy: 0.9894914398635796\n",
      "test_loss: 1.7004115125209606e-05, test_accuracy: 0.9889970984515499\n",
      "Epoch 24, train_loss: 6.38943052306676e-05, train_accuracy: 0.9895653137485456\n",
      "test_loss: 1.741369564471795e-05, test_accuracy: 0.9890545548565026\n",
      "Epoch 25, train_loss: 6.327108375350691e-05, train_accuracy: 0.9897684669322022\n",
      "test_loss: 1.6966851867953493e-05, test_accuracy: 0.9890689189577409\n",
      "Epoch 26, train_loss: 6.342058106485407e-05, train_accuracy: 0.9896761245759946\n",
      "test_loss: 1.773226733507738e-05, test_accuracy: 0.9889396420465971\n",
      "Epoch 27, train_loss: 6.298538138279415e-05, train_accuracy: 0.9898238723459267\n",
      "test_loss: 1.7616403920000686e-05, test_accuracy: 0.9887529087305007\n",
      "Epoch 28, train_loss: 6.225334922573666e-05, train_accuracy: 0.9897684669322022\n",
      "test_loss: 1.7117568884592725e-05, test_accuracy: 0.9889970984515499\n",
      "Epoch 29, train_loss: 6.245854506973212e-05, train_accuracy: 0.9897438423038802\n",
      "test_loss: 1.6926259592014097e-05, test_accuracy: 0.9890401907552644\n",
      "Epoch 30, train_loss: 6.242163998152099e-05, train_accuracy: 0.9895714699056262\n",
      "test_loss: 1.6892386382106062e-05, test_accuracy: 0.9890258266540263\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# corpus_reddit = pd.read_csv('reddit_corpus_agree.csv')\n",
    "# corpus_reddit['label'] = 0\n",
    "# corpus_reddit['label'].loc[(corpus_reddit['cls']=='Risk')] = 1 \n",
    "# del corpus_reddit['cls']\n",
    "\n",
    "# batch_size = 1\n",
    "# texts, labels =  corpus_reddit['text'], corpus_reddit['label']\n",
    "# #texts = [\" \".join(text.split()[:512]) if len(text.split())>512 else text for text in texts]\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.1, stratify=corpus_reddit['label'])\n",
    "# model_name = 'bert-base-uncased'\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = BertConfig.from_pretrained(model_name, output_hidden_states=False)  \n",
    "best_bert_model = torch.load('trained_all_sideselected.pt')  \n",
    "bert_model = BertModel.from_pretrained(model_name, config=config)\n",
    "bert_model = bert_model.to(device)\n",
    "bert_model.load_state_dict(best_bert_model.bert.state_dict())\n",
    "bert_model.eval()\n",
    "\n",
    "# train_embeddings = embeddings_from_dataset(X_train, tokenizer, bert_model)\n",
    "# test_embeddings = embeddings_from_dataset(X_test, tokenizer, bert_model)\n",
    "\n",
    "train_dataset = data_utils.TensorDataset(train_embeddings , torch.Tensor(side_features_train[selected_features].values), train_labels)\n",
    "test_dataset = data_utils.TensorDataset(val_embeddings , torch.Tensor(side_features_val[selected_features].values), val_labels)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = data_utils.DataLoader(test_dataset, batch_size=2048)\n",
    "\n",
    "classifier_nn = BertNet(bert_model, tokenizer,input_size = 768+len(selected_features))\n",
    "classifier_nn = classifier_nn.to(device)\n",
    "optimizer = torch.optim.Adam(classifier_nn.parameters(),lr=0.002)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(30):\n",
    "    train_loss, train_accuracy = train_model(classifier_nn,optimizer,criterion,train_loader)\n",
    "    print(f\"Epoch {epoch+1}, train_loss: {train_loss}, train_accuracy: {train_accuracy}\")\n",
    "    test_loss, test_accuracy = test_model(classifier_nn,criterion,test_loader)\n",
    "    print(f\"test_loss: {test_loss}, test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier_nn,'classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=775, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_nn.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASD\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\ASD\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train:  185645 len test:  46412\n"
     ]
    }
   ],
   "source": [
    "#CLASSİCAL METHODS ONLY FEATURES START HERE\n",
    "dataset = pd.read_csv(\"LIWC-results.csv\")\n",
    "dataset = dataset.drop(\"Unnamed: 0\",1)\n",
    "dataset = dataset.drop(\"Unnamed: 0.1\",1)\n",
    "#dataset = dataset.drop(\"text\",1)\n",
    "dataset = dataset.dropna()\n",
    "labels = dataset[\"class\"]\n",
    "datapoints = dataset['text']\n",
    "labels = labels.astype(\"int\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set,test_set,train_labels,test_labels = train_test_split(datapoints,labels,test_size=0.2,shuffle= True, stratify=labels)\n",
    "print(\"len train: \",len(train_set),\"len test: \",len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [1., 2., 1.],\n",
       "        [2., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data no : 0\n",
      "data no : 100\n",
      "data no : 200\n",
      "data no : 300\n",
      "data no : 400\n",
      "data no : 500\n",
      "data no : 600\n",
      "data no : 700\n",
      "data no : 800\n",
      "data no : 900\n",
      "data no : 1000\n",
      "data no : 1100\n",
      "data no : 1200\n",
      "data no : 1300\n",
      "data no : 1400\n",
      "data no : 1500\n",
      "data no : 1600\n",
      "data no : 1700\n",
      "data no : 1800\n",
      "data no : 1900\n",
      "data no : 0\n",
      "data no : 100\n",
      "data no : 200\n",
      "data no : 300\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = BertConfig.from_pretrained(model_name, output_hidden_states=False)    \n",
    "bert_model = BertModel.from_pretrained(model_name, config=config)\n",
    "bert_model = bert_model.to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "train_embeddings = embeddings_from_dataset(train_set.iloc[:2000], tokenizer, bert_model)\n",
    "test_embeddings = embeddings_from_dataset(test_set.iloc[:400], tokenizer, bert_model)\n",
    "\n",
    "train_dataset = data_utils.TensorDataset(train_embeddings , torch.FloatTensor(train_labels.iloc[:2000].values).view(-1,1))\n",
    "test_dataset = data_utils.TensorDataset(test_embeddings , torch.FloatTensor(test_labels.iloc[:400].values).view(-1,1))\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,batch_size=10,shuffle=True)\n",
    "test_loader = data_utils.DataLoader(test_dataset,batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 0.03305102943629026, train_accuracy: 0.868\n",
      "test_loss: 0.26898272114773136, test_accuracy: 0.89\n",
      "Epoch 2, train_loss: 0.022328932769130914, train_accuracy: 0.917\n",
      "test_loss: 0.23238260208097927, test_accuracy: 0.8975\n",
      "Epoch 3, train_loss: 0.02041545647964813, train_accuracy: 0.922\n",
      "test_loss: 0.2599868453106285, test_accuracy: 0.9075\n",
      "Epoch 4, train_loss: 0.018962690729647874, train_accuracy: 0.933\n",
      "test_loss: 0.28062685343033084, test_accuracy: 0.8975\n",
      "Epoch 5, train_loss: 0.01739352177793626, train_accuracy: 0.9345\n",
      "test_loss: 0.2798020233371517, test_accuracy: 0.9\n",
      "Epoch 6, train_loss: 0.015553986871382222, train_accuracy: 0.9455\n",
      "test_loss: 0.24166877980842172, test_accuracy: 0.9\n",
      "Epoch 7, train_loss: 0.013869951889500954, train_accuracy: 0.9465\n",
      "test_loss: 0.301289434963616, test_accuracy: 0.8875\n",
      "Epoch 8, train_loss: 0.014024376036133617, train_accuracy: 0.9485\n",
      "test_loss: 0.2713669410789562, test_accuracy: 0.9125\n",
      "Epoch 9, train_loss: 0.014319379289678181, train_accuracy: 0.947\n",
      "test_loss: 0.2439456634749132, test_accuracy: 0.905\n",
      "Epoch 10, train_loss: 0.011639987361078966, train_accuracy: 0.955\n",
      "test_loss: 0.24962459834680983, test_accuracy: 0.895\n",
      "Epoch 11, train_loss: 0.01074616808112478, train_accuracy: 0.956\n",
      "test_loss: 0.39363251947646277, test_accuracy: 0.9075\n",
      "Epoch 12, train_loss: 0.009831808096481836, train_accuracy: 0.9565\n",
      "test_loss: 0.2962154997981402, test_accuracy: 0.905\n",
      "Epoch 13, train_loss: 0.008924378109532881, train_accuracy: 0.969\n",
      "test_loss: 0.3232032365674546, test_accuracy: 0.9025\n",
      "Epoch 14, train_loss: 0.009026950836472678, train_accuracy: 0.9655\n",
      "test_loss: 0.38858274902807693, test_accuracy: 0.89\n",
      "Epoch 15, train_loss: 0.009087529669688593, train_accuracy: 0.9685\n",
      "test_loss: 0.32799779370826987, test_accuracy: 0.915\n",
      "Epoch 16, train_loss: 0.005907725185392337, train_accuracy: 0.98\n",
      "test_loss: 0.4550108949214011, test_accuracy: 0.8975\n",
      "Epoch 17, train_loss: 0.0064978915008014155, train_accuracy: 0.9775\n",
      "test_loss: 0.40383956876287086, test_accuracy: 0.91\n",
      "Epoch 18, train_loss: 0.006917261104138561, train_accuracy: 0.9685\n",
      "test_loss: 0.4195120216773829, test_accuracy: 0.91\n",
      "Epoch 19, train_loss: 0.004413695110620779, train_accuracy: 0.983\n",
      "test_loss: 0.5221665788564762, test_accuracy: 0.9075\n",
      "Epoch 20, train_loss: 0.006957866970839405, train_accuracy: 0.9775\n",
      "test_loss: 0.33377590542810387, test_accuracy: 0.8825\n",
      "Epoch 21, train_loss: 0.005945045347045152, train_accuracy: 0.9805\n",
      "test_loss: 0.4660565908542486, test_accuracy: 0.9125\n",
      "Epoch 22, train_loss: 0.0045419591083809795, train_accuracy: 0.983\n",
      "test_loss: 0.4935393427000958, test_accuracy: 0.9125\n",
      "Epoch 23, train_loss: 0.005437979940379592, train_accuracy: 0.9795\n",
      "test_loss: 0.49715869055008227, test_accuracy: 0.91\n",
      "Epoch 24, train_loss: 0.0035010093477112606, train_accuracy: 0.9855\n",
      "test_loss: 0.4785762098498337, test_accuracy: 0.9175\n",
      "Epoch 25, train_loss: 0.004640130490702859, train_accuracy: 0.9835\n",
      "test_loss: 0.45381234641835577, test_accuracy: 0.9025\n",
      "Epoch 26, train_loss: 0.005665804241967208, train_accuracy: 0.98\n",
      "test_loss: 0.6073348502057899, test_accuracy: 0.9\n",
      "Epoch 27, train_loss: 0.0028341645373898246, train_accuracy: 0.9885\n",
      "test_loss: 0.8584381830307204, test_accuracy: 0.9025\n",
      "Epoch 28, train_loss: 0.0035577620181020393, train_accuracy: 0.989\n",
      "test_loss: 0.8753100259921662, test_accuracy: 0.895\n",
      "Epoch 29, train_loss: 0.0019909203221613013, train_accuracy: 0.994\n",
      "test_loss: 0.4959613337355435, test_accuracy: 0.905\n",
      "Epoch 30, train_loss: 0.002711162518670591, train_accuracy: 0.989\n",
      "test_loss: 0.814019142698769, test_accuracy: 0.9075\n"
     ]
    }
   ],
   "source": [
    "my_NN = BertNet(bert_model, tokenizer)\n",
    "optimizer = torch.optim.Adam(my_NN.parameters(),lr=0.01)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(30):\n",
    "    train_loss, train_accuracy = train_model(my_NN,optimizer,criterion,train_loader)\n",
    "    print(f\"Epoch {epoch+1}, train_loss: {train_loss}, train_accuracy: {train_accuracy}\")\n",
    "    test_loss, test_accuracy = test_model(my_NN,criterion,test_loader)\n",
    "    print(f\"test_loss: {test_loss}, test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 0.001642594085657523, train_accuracy: 0.8241924660949649\n",
      "test_loss: 0.0015178968979930223, test_accuracy: 0.8385905943865093\n",
      "Epoch 2, train_loss: 0.0014776372685861984, train_accuracy: 0.8418483246018506\n",
      "test_loss: 0.0014372181426982556, test_accuracy: 0.8464908500675112\n",
      "Epoch 3, train_loss: 0.001460064214954082, train_accuracy: 0.8436336101551967\n",
      "test_loss: 0.0014423135804062879, test_accuracy: 0.8459019219167456\n",
      "Epoch 4, train_loss: 0.00144158124223593, train_accuracy: 0.8445447214031113\n",
      "test_loss: 0.0014327887268354626, test_accuracy: 0.8458301014105547\n",
      "Epoch 5, train_loss: 0.0014367897162864463, train_accuracy: 0.8455173942218309\n",
      "test_loss: 0.0014418961261455678, test_accuracy: 0.8465195782699877\n",
      "Epoch 6, train_loss: 0.0014357381509024199, train_accuracy: 0.8450249016553907\n",
      "test_loss: 0.0014360980384772906, test_accuracy: 0.8480421730012353\n",
      "Epoch 7, train_loss: 0.0014321851783112012, train_accuracy: 0.8458128897616951\n",
      "test_loss: 0.001431482273981152, test_accuracy: 0.8482863627222844\n",
      "Epoch 8, train_loss: 0.0014279102359793427, train_accuracy: 0.8460837606732373\n",
      "test_loss: 0.0014219027224594985, test_accuracy: 0.8483869114309518\n",
      "Epoch 9, train_loss: 0.0014252332005723215, train_accuracy: 0.8459483252174662\n",
      "test_loss: 0.0014215613895921632, test_accuracy: 0.8476974345715189\n",
      "Epoch 10, train_loss: 0.0014279219971812503, train_accuracy: 0.8454989257505895\n",
      "test_loss: 0.0014139520195263434, test_accuracy: 0.8485449165445718\n",
      "Epoch 11, train_loss: 0.0014185023273748673, train_accuracy: 0.8470995265915205\n",
      "test_loss: 0.0014089491073743248, test_accuracy: 0.8498089574535321\n",
      "Epoch 12, train_loss: 0.0014206533764406417, train_accuracy: 0.8466439709675632\n",
      "test_loss: 0.0014342762688883055, test_accuracy: 0.8477261627739953\n",
      "Epoch 13, train_loss: 0.0014187574505116864, train_accuracy: 0.8470625896490375\n",
      "test_loss: 0.0014115006883983628, test_accuracy: 0.8493062139101957\n",
      "Epoch 14, train_loss: 0.0014165618362053012, train_accuracy: 0.8475243014300753\n",
      "test_loss: 0.001443527229022177, test_accuracy: 0.8456720962969347\n",
      "Epoch 15, train_loss: 0.0014165934238526364, train_accuracy: 0.8472718989897746\n",
      "test_loss: 0.0014122055883658826, test_accuracy: 0.8490476600879083\n",
      "Epoch 16, train_loss: 0.0014123966659474296, train_accuracy: 0.8477028299854099\n",
      "test_loss: 0.0014100930481449636, test_accuracy: 0.8484012755321899\n",
      "Epoch 17, train_loss: 0.001414136298795274, train_accuracy: 0.8474812083305118\n",
      "test_loss: 0.0014104400300031666, test_accuracy: 0.8497802292510558\n",
      "Epoch 18, train_loss: 0.0014122087057774355, train_accuracy: 0.8478936708549055\n",
      "test_loss: 0.0014383599404825132, test_accuracy: 0.8461892039415094\n",
      "Epoch 19, train_loss: 0.001410938433408906, train_accuracy: 0.8475181452729947\n",
      "test_loss: 0.0014132773769340524, test_accuracy: 0.8494642190238156\n",
      "Epoch 20, train_loss: 0.001415761973384841, train_accuracy: 0.8473519290318212\n",
      "test_loss: 0.001418286587907807, test_accuracy: 0.84855928064581\n",
      "Epoch 21, train_loss: 0.001412678573912092, train_accuracy: 0.8481460732952062\n",
      "test_loss: 0.0014073013088101716, test_accuracy: 0.8489614754804792\n",
      "Epoch 22, train_loss: 0.0014093747443254692, train_accuracy: 0.8476227999433633\n",
      "test_loss: 0.0014315828993065054, test_accuracy: 0.8470223218133242\n",
      "Epoch 23, train_loss: 0.0014098740548187329, train_accuracy: 0.8484169442067484\n",
      "test_loss: 0.0014134279574722966, test_accuracy: 0.849176936999052\n",
      "Epoch 24, train_loss: 0.001408227891098124, train_accuracy: 0.8483615387930239\n",
      "test_loss: 0.0014154041796154702, test_accuracy: 0.8492056652015283\n",
      "Epoch 25, train_loss: 0.0014067682115492355, train_accuracy: 0.8477028299854099\n",
      "test_loss: 0.001406596968775969, test_accuracy: 0.8495360395300066\n",
      "Epoch 26, train_loss: 0.0014078137736840987, train_accuracy: 0.8481953225518503\n",
      "test_loss: 0.0014150132618275372, test_accuracy: 0.8494929472262921\n",
      "Epoch 27, train_loss: 0.001406509464923801, train_accuracy: 0.8486385658616465\n",
      "test_loss: 0.0014270239355077198, test_accuracy: 0.846849952598466\n",
      "Epoch 28, train_loss: 0.0014078740033118596, train_accuracy: 0.8487370643749346\n",
      "test_loss: 0.0014111292805194019, test_accuracy: 0.849018931885432\n",
      "Epoch 29, train_loss: 0.0014077915588551371, train_accuracy: 0.848533911191278\n",
      "test_loss: 0.0014134591155353692, test_accuracy: 0.8486741934557155\n",
      "Epoch 30, train_loss: 0.0014053639374346197, train_accuracy: 0.8484107880496679\n",
      "test_loss: 0.001414541136585254, test_accuracy: 0.8491913011002902\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('processed_dataset_sf.pt')\n",
    "train_inputs = data['train_inputs']\n",
    "train_masks = data['train_masks']\n",
    "train_labels = data['train_labels']\n",
    "side_features_train = data['side_features_train']\n",
    "val_inputs = data['val_inputs']\n",
    "val_masks = data['val_masks']\n",
    "val_labels = data['val_labels']\n",
    "side_features_val = data['side_features_val']\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 256\n",
    "# Create the DataLoader for our training set\n",
    "train_data = data_utils.TensorDataset(torch.Tensor(side_features_train[selected_features].values), train_labels)\n",
    "train_sampler = data_utils.RandomSampler(train_data)\n",
    "train_dataloader = data_utils.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = data_utils.TensorDataset(torch.Tensor(side_features_val[selected_features].values), val_labels)\n",
    "val_sampler = data_utils.SequentialSampler(val_data)\n",
    "val_dataloader = data_utils.DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "sf_classifier = SFNet(len(selected_features))\n",
    "optimizer = torch.optim.Adam(sf_classifier.parameters(), lr =0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "sf_classifier.to(device)\n",
    "\n",
    "for epoch in range(30):\n",
    "    train_loss, train_accuracy = train_model(sf_classifier,optimizer,criterion,train_dataloader, use_sf=False)\n",
    "    print(f\"Epoch {epoch+1}, train_loss: {train_loss}, train_accuracy: {train_accuracy}\")\n",
    "    test_loss, test_accuracy = test_model(sf_classifier,criterion,val_dataloader, use_sf=False)\n",
    "    print(f\"test_loss: {test_loss}, test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.027823300899997835, 0.7763440860215054)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader = create_kaggle_test_liwc_dataset(use_bert =False,use_sf=True)\n",
    "test_model(sf_classifier,criterion,test_dataloader,use_sf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.022168608316158887, 0.8451776649746193)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader = create_test_liwc_dataset(use_bert =False,use_sf=True)\n",
    "test_model(sf_classifier,criterion,test_dataloader,use_sf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 3.],\n",
       "       [2., 2.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.array([1,0,1,0]),np.array([1,1,0,1])) + np.ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00714c0258f0252411be26c69aff889ba5b83731fc950bc03012d018ebcc42e9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('pytorchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
